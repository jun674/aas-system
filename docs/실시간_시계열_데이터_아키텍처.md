# 실시간 시계열 데이터 처리 아키텍처

## 🚨 문제점

- AAS Repository는 정적 메타데이터 저장에 적합
- 실시간으로 계속 변경되는 센서 데이터를 매번 업데이트하면 성능 저하
- BaSyx는 시계열 데이터 저장에 최적화되어 있지 않음

## 💡 해결방안: 하이브리드 아키텍처

### 전체 아키텍처

```
[애니토이 센서] → [Data Ingestion] → [시계열 DB] ← [AAS Repository]
                                          ↓              ↓
                                    [Query Service] → [Frontend]
```

### 1. 데이터 분리 전략

#### 정적 데이터 (AAS Repository에 저장)

```json
{
  "assetId": "PUMP-001",
  "idShort": "CentrifugalPump",
  "manufacturer": "애니토이",
  "model": "AT-2000",
  "serialNumber": "2024-001",
  "specifications": {
    "maxPressure": "10 bar",
    "maxFlow": "100 m³/h",
    "power": "15 kW"
  },
  "dataSource": {
    "type": "timeseries",
    "endpoint": "http://timeseries-db/api/v1/data/PUMP-001",
    "measurementPoints": [
      {
        "name": "pressure",
        "unit": "bar",
        "dataType": "float"
      },
      {
        "name": "temperature",
        "unit": "°C",
        "dataType": "float"
      }
    ]
  }
}
```

#### 동적 데이터 (시계열 DB에 저장)

```json
{
  "assetId": "PUMP-001",
  "timestamp": "2024-01-11T10:30:00Z",
  "measurements": {
    "pressure": 8.5,
    "temperature": 45.2,
    "flowRate": 85.3,
    "vibration": 0.12
  }
}
```

### 2. 시계열 데이터베이스 옵션

#### Option 1: InfluxDB (추천)

```yaml
# docker-compose.yml
services:
  influxdb:
    image: influxdb:2.7
    ports:
      - '8086:8086'
    environment:
      - INFLUXDB_DB=aas_timeseries
      - INFLUXDB_ADMIN_USER=admin
      - INFLUXDB_ADMIN_PASSWORD=secure_password
    volumes:
      - influxdb-data:/var/lib/influxdb2
```

**장점:**

- 시계열 데이터에 최적화
- 높은 쓰기 성능
- 자동 데이터 압축
- 보존 정책 설정 가능

#### Option 2: TimescaleDB (PostgreSQL 확장)

```sql
-- TimescaleDB 설정
CREATE TABLE sensor_data (
    time        TIMESTAMPTZ NOT NULL,
    asset_id    TEXT NOT NULL,
    pressure    DOUBLE PRECISION,
    temperature DOUBLE PRECISION,
    flow_rate   DOUBLE PRECISION,
    vibration   DOUBLE PRECISION
);

-- 하이퍼테이블 생성
SELECT create_hypertable('sensor_data', 'time');

-- 인덱스 생성
CREATE INDEX idx_asset_time ON sensor_data (asset_id, time DESC);
```

**장점:**

- PostgreSQL의 모든 기능 사용 가능
- SQL 쿼리 지원
- 복잡한 분석 쿼리 가능

#### Option 3: Apache Kafka + Druid

- 대용량 실시간 스트리밍에 적합
- 복잡도가 높아 소규모에는 과도함

### 3. 데이터 수집 서비스

```java
// DataIngestionService.java
@Service
@Slf4j
public class DataIngestionService {

    @Autowired
    private InfluxDBClient influxDBClient;

    @Autowired
    private KafkaTemplate<String, SensorData> kafkaTemplate;

    // 실시간 데이터 수신 API
    @PostMapping("/api/timeseries/ingest")
    public ResponseEntity<?> ingestData(@RequestBody SensorData data) {
        try {
            // 1. 데이터 검증
            validateSensorData(data);

            // 2. Kafka로 전송 (비동기 처리)
            kafkaTemplate.send("sensor-data-topic", data.getAssetId(), data);

            return ResponseEntity.accepted().build();

        } catch (Exception e) {
            log.error("Data ingestion failed", e);
            return ResponseEntity.badRequest().body(e.getMessage());
        }
    }

    // Kafka Consumer - 배치 처리
    @KafkaListener(topics = "sensor-data-topic")
    public void processSensorData(List<SensorData> batch) {
        // InfluxDB에 배치 저장
        List<Point> points = batch.stream()
            .map(this::convertToInfluxPoint)
            .collect(Collectors.toList());

        influxDBClient.writePoints(points);
    }

    private Point convertToInfluxPoint(SensorData data) {
        return Point.measurement("sensor_data")
            .time(data.getTimestamp(), WritePrecision.MS)
            .tag("asset_id", data.getAssetId())
            .field("pressure", data.getPressure())
            .field("temperature", data.getTemperature())
            .field("flow_rate", data.getFlowRate())
            .field("vibration", data.getVibration())
            .build();
    }
}
```

### 4. 쿼리 서비스

```java
// TimeSeriesQueryService.java
@Service
public class TimeSeriesQueryService {

    @Autowired
    private InfluxDBClient influxDBClient;

    // 최신 값 조회
    @GetMapping("/api/timeseries/{assetId}/current")
    public ResponseEntity<?> getCurrentValues(@PathVariable String assetId) {
        String query = String.format(
            "from(bucket: \"aas_timeseries\") " +
            "|> range(start: -1m) " +
            "|> filter(fn: (r) => r.asset_id == \"%s\") " +
            "|> last()",
            assetId
        );

        List<FluxTable> tables = influxDBClient.getQueryApi().query(query);
        return ResponseEntity.ok(convertToJson(tables));
    }

    // 시간 범위 조회
    @GetMapping("/api/timeseries/{assetId}/history")
    public ResponseEntity<?> getHistoricalData(
            @PathVariable String assetId,
            @RequestParam String start,
            @RequestParam String end,
            @RequestParam(defaultValue = "1m") String interval) {

        String query = String.format(
            "from(bucket: \"aas_timeseries\") " +
            "|> range(start: %s, stop: %s) " +
            "|> filter(fn: (r) => r.asset_id == \"%s\") " +
            "|> aggregateWindow(every: %s, fn: mean)",
            start, end, assetId, interval
        );

        List<FluxTable> tables = influxDBClient.getQueryApi().query(query);
        return ResponseEntity.ok(convertToJson(tables));
    }

    // 통계 조회
    @GetMapping("/api/timeseries/{assetId}/stats")
    public ResponseEntity<?> getStatistics(
            @PathVariable String assetId,
            @RequestParam String period) {

        String query = String.format(
            "from(bucket: \"aas_timeseries\") " +
            "|> range(start: -%s) " +
            "|> filter(fn: (r) => r.asset_id == \"%s\") " +
            "|> group(columns: [\"_field\"]) " +
            "|> reduce(fn: (r, accumulator) => ({" +
            "    count: accumulator.count + 1," +
            "    sum: accumulator.sum + r._value," +
            "    min: if r._value < accumulator.min then r._value else accumulator.min," +
            "    max: if r._value > accumulator.max then r._value else accumulator.max" +
            "}))",
            period, assetId
        );

        List<FluxTable> tables = influxDBClient.getQueryApi().query(query);
        return ResponseEntity.ok(convertToJson(tables));
    }
}
```

### 5. AAS와 시계열 데이터 통합

```java
// AasTimeSeriesIntegrationService.java
@Service
public class AasTimeSeriesIntegrationService {

    @Autowired
    private AasRepository aasRepository;

    @Autowired
    private TimeSeriesQueryService timeSeriesService;

    // AAS 정보와 실시간 데이터 통합 조회
    @GetMapping("/api/aas/{aasId}/with-realtime")
    public ResponseEntity<?> getAasWithRealtimeData(@PathVariable String aasId) {
        // 1. AAS 정적 정보 조회
        AssetAdministrationShell aas = aasRepository.findById(aasId);

        // 2. 현재 센서 값 조회
        Map<String, Object> currentValues = timeSeriesService
            .getCurrentValues(aas.getAssetId());

        // 3. 통합 응답
        Map<String, Object> response = new HashMap<>();
        response.put("aas", aas);
        response.put("currentValues", currentValues);
        response.put("dataSourceUrl", "/api/timeseries/" + aas.getAssetId());

        return ResponseEntity.ok(response);
    }
}
```

### 6. 프론트엔드 통합

```javascript
// useTimeSeriesData.js
import { ref, onMounted, onUnmounted } from 'vue'
import axios from 'axios'

export function useTimeSeriesData(assetId) {
  const currentData = ref({})
  const historicalData = ref([])
  const isLoading = ref(false)
  let intervalId = null

  // 실시간 데이터 폴링
  const fetchCurrentData = async () => {
    try {
      const response = await axios.get(`/api/timeseries/${assetId}/current`)
      currentData.value = response.data
    } catch (error) {
      console.error('Failed to fetch current data:', error)
    }
  }

  // 히스토리 데이터 조회
  const fetchHistoricalData = async (start, end, interval = '1m') => {
    isLoading.value = true
    try {
      const response = await axios.get(`/api/timeseries/${assetId}/history`, {
        params: { start, end, interval },
      })
      historicalData.value = response.data
    } catch (error) {
      console.error('Failed to fetch historical data:', error)
    } finally {
      isLoading.value = false
    }
  }

  // 실시간 업데이트 시작
  const startRealTimeUpdates = (intervalMs = 5000) => {
    fetchCurrentData() // 즉시 한번 실행
    intervalId = setInterval(fetchCurrentData, intervalMs)
  }

  // 실시간 업데이트 중지
  const stopRealTimeUpdates = () => {
    if (intervalId) {
      clearInterval(intervalId)
      intervalId = null
    }
  }

  onMounted(() => {
    startRealTimeUpdates()
  })

  onUnmounted(() => {
    stopRealTimeUpdates()
  })

  return {
    currentData,
    historicalData,
    isLoading,
    fetchHistoricalData,
    startRealTimeUpdates,
    stopRealTimeUpdates,
  }
}
```

### 7. 성능 최적화 전략

#### 데이터 보존 정책

```sql
-- InfluxDB 보존 정책
CREATE RETENTION POLICY "one_week" ON "aas_timeseries" DURATION 1w REPLICATION 1 DEFAULT
CREATE RETENTION POLICY "one_month" ON "aas_timeseries" DURATION 4w REPLICATION 1
CREATE RETENTION POLICY "one_year" ON "aas_timeseries" DURATION 52w REPLICATION 1

-- 연속 쿼리로 다운샘플링
CREATE CONTINUOUS QUERY "downsample_1h" ON "aas_timeseries"
BEGIN
  SELECT mean(*) INTO "one_month"."downsampled"
  FROM "one_week"."sensor_data"
  GROUP BY time(1h), *
END
```

#### 캐싱 전략

```java
@Configuration
@EnableCaching
public class CacheConfig {

    @Bean
    public CacheManager cacheManager() {
        return new ConcurrentMapCacheManager("currentValues", "statistics");
    }
}

// 서비스에서 캐시 사용
@Cacheable(value = "currentValues", key = "#assetId")
public Map<String, Object> getCurrentValues(String assetId) {
    // 실제 조회 로직
}

@CacheEvict(value = "currentValues", key = "#assetId")
@Scheduled(fixedDelay = 5000) // 5초마다 캐시 갱신
public void evictCurrentValuesCache() {
    // 캐시 무효화
}
```

### 8. 모니터링 및 알림

```java
// AlertingService.java
@Service
public class AlertingService {

    @Value("${alert.threshold.pressure.max}")
    private double maxPressure;

    @EventListener
    public void checkThresholds(SensorDataEvent event) {
        SensorData data = event.getSensorData();

        // 임계값 체크
        if (data.getPressure() > maxPressure) {
            sendAlert(AlertType.HIGH_PRESSURE, data);
        }

        // 이상 패턴 감지
        if (isAnomalous(data)) {
            sendAlert(AlertType.ANOMALY, data);
        }
    }

    private void sendAlert(AlertType type, SensorData data) {
        // 알림 발송 로직
        notificationService.send(
            String.format("Alert: %s detected for asset %s",
                type, data.getAssetId())
        );
    }
}
```

## 📊 아키텍처 비교

| 항목        | 직접 업데이트 방식 | 시계열 DB 분리 방식 |
| ----------- | ------------------ | ------------------- |
| 쓰기 성능   | ❌ 낮음            | ✅ 높음             |
| 조회 성능   | ❌ 낮음            | ✅ 높음             |
| 확장성      | ❌ 제한적          | ✅ 우수             |
| 데이터 압축 | ❌ 없음            | ✅ 자동             |
| 시계열 분석 | ❌ 어려움          | ✅ 쉬움             |
| 구현 복잡도 | ✅ 단순            | ⚠️ 중간             |
| 유지보수    | ❌ 어려움          | ✅ 쉬움             |

## 🎯 권장사항

1. **소규모 시작**: InfluxDB + 단순 폴링
2. **중규모**: InfluxDB + Kafka + 캐싱
3. **대규모**: TimescaleDB/Druid + Kafka + Redis

이 아키텍처를 사용하면 AAS의 정적 정보와 실시간 센서 데이터를 효율적으로 분리 관리할 수 있습니다.
