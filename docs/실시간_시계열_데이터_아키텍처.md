# ì‹¤ì‹œê°„ ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬ ì•„í‚¤í…ì²˜

## ğŸš¨ ë¬¸ì œì 

- AAS RepositoryëŠ” ì •ì  ë©”íƒ€ë°ì´í„° ì €ì¥ì— ì í•©
- ì‹¤ì‹œê°„ìœ¼ë¡œ ê³„ì† ë³€ê²½ë˜ëŠ” ì„¼ì„œ ë°ì´í„°ë¥¼ ë§¤ë²ˆ ì—…ë°ì´íŠ¸í•˜ë©´ ì„±ëŠ¥ ì €í•˜
- BaSyxëŠ” ì‹œê³„ì—´ ë°ì´í„° ì €ì¥ì— ìµœì í™”ë˜ì–´ ìˆì§€ ì•ŠìŒ

## ğŸ’¡ í•´ê²°ë°©ì•ˆ: í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜

### ì „ì²´ ì•„í‚¤í…ì²˜

```
[ì• ë‹ˆí† ì´ ì„¼ì„œ] â†’ [Data Ingestion] â†’ [ì‹œê³„ì—´ DB] â† [AAS Repository]
                                          â†“              â†“
                                    [Query Service] â†’ [Frontend]
```

### 1. ë°ì´í„° ë¶„ë¦¬ ì „ëµ

#### ì •ì  ë°ì´í„° (AAS Repositoryì— ì €ì¥)

```json
{
  "assetId": "PUMP-001",
  "idShort": "CentrifugalPump",
  "manufacturer": "ì• ë‹ˆí† ì´",
  "model": "AT-2000",
  "serialNumber": "2024-001",
  "specifications": {
    "maxPressure": "10 bar",
    "maxFlow": "100 mÂ³/h",
    "power": "15 kW"
  },
  "dataSource": {
    "type": "timeseries",
    "endpoint": "http://timeseries-db/api/v1/data/PUMP-001",
    "measurementPoints": [
      {
        "name": "pressure",
        "unit": "bar",
        "dataType": "float"
      },
      {
        "name": "temperature",
        "unit": "Â°C",
        "dataType": "float"
      }
    ]
  }
}
```

#### ë™ì  ë°ì´í„° (ì‹œê³„ì—´ DBì— ì €ì¥)

```json
{
  "assetId": "PUMP-001",
  "timestamp": "2024-01-11T10:30:00Z",
  "measurements": {
    "pressure": 8.5,
    "temperature": 45.2,
    "flowRate": 85.3,
    "vibration": 0.12
  }
}
```

### 2. ì‹œê³„ì—´ ë°ì´í„°ë² ì´ìŠ¤ ì˜µì…˜

#### Option 1: InfluxDB (ì¶”ì²œ)

```yaml
# docker-compose.yml
services:
  influxdb:
    image: influxdb:2.7
    ports:
      - '8086:8086'
    environment:
      - INFLUXDB_DB=aas_timeseries
      - INFLUXDB_ADMIN_USER=admin
      - INFLUXDB_ADMIN_PASSWORD=secure_password
    volumes:
      - influxdb-data:/var/lib/influxdb2
```

**ì¥ì :**

- ì‹œê³„ì—´ ë°ì´í„°ì— ìµœì í™”
- ë†’ì€ ì“°ê¸° ì„±ëŠ¥
- ìë™ ë°ì´í„° ì••ì¶•
- ë³´ì¡´ ì •ì±… ì„¤ì • ê°€ëŠ¥

#### Option 2: TimescaleDB (PostgreSQL í™•ì¥)

```sql
-- TimescaleDB ì„¤ì •
CREATE TABLE sensor_data (
    time        TIMESTAMPTZ NOT NULL,
    asset_id    TEXT NOT NULL,
    pressure    DOUBLE PRECISION,
    temperature DOUBLE PRECISION,
    flow_rate   DOUBLE PRECISION,
    vibration   DOUBLE PRECISION
);

-- í•˜ì´í¼í…Œì´ë¸” ìƒì„±
SELECT create_hypertable('sensor_data', 'time');

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_asset_time ON sensor_data (asset_id, time DESC);
```

**ì¥ì :**

- PostgreSQLì˜ ëª¨ë“  ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥
- SQL ì¿¼ë¦¬ ì§€ì›
- ë³µì¡í•œ ë¶„ì„ ì¿¼ë¦¬ ê°€ëŠ¥

#### Option 3: Apache Kafka + Druid

- ëŒ€ìš©ëŸ‰ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì— ì í•©
- ë³µì¡ë„ê°€ ë†’ì•„ ì†Œê·œëª¨ì—ëŠ” ê³¼ë„í•¨

### 3. ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤

```java
// DataIngestionService.java
@Service
@Slf4j
public class DataIngestionService {

    @Autowired
    private InfluxDBClient influxDBClient;

    @Autowired
    private KafkaTemplate<String, SensorData> kafkaTemplate;

    // ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì‹  API
    @PostMapping("/api/timeseries/ingest")
    public ResponseEntity<?> ingestData(@RequestBody SensorData data) {
        try {
            // 1. ë°ì´í„° ê²€ì¦
            validateSensorData(data);

            // 2. Kafkaë¡œ ì „ì†¡ (ë¹„ë™ê¸° ì²˜ë¦¬)
            kafkaTemplate.send("sensor-data-topic", data.getAssetId(), data);

            return ResponseEntity.accepted().build();

        } catch (Exception e) {
            log.error("Data ingestion failed", e);
            return ResponseEntity.badRequest().body(e.getMessage());
        }
    }

    // Kafka Consumer - ë°°ì¹˜ ì²˜ë¦¬
    @KafkaListener(topics = "sensor-data-topic")
    public void processSensorData(List<SensorData> batch) {
        // InfluxDBì— ë°°ì¹˜ ì €ì¥
        List<Point> points = batch.stream()
            .map(this::convertToInfluxPoint)
            .collect(Collectors.toList());

        influxDBClient.writePoints(points);
    }

    private Point convertToInfluxPoint(SensorData data) {
        return Point.measurement("sensor_data")
            .time(data.getTimestamp(), WritePrecision.MS)
            .tag("asset_id", data.getAssetId())
            .field("pressure", data.getPressure())
            .field("temperature", data.getTemperature())
            .field("flow_rate", data.getFlowRate())
            .field("vibration", data.getVibration())
            .build();
    }
}
```

### 4. ì¿¼ë¦¬ ì„œë¹„ìŠ¤

```java
// TimeSeriesQueryService.java
@Service
public class TimeSeriesQueryService {

    @Autowired
    private InfluxDBClient influxDBClient;

    // ìµœì‹  ê°’ ì¡°íšŒ
    @GetMapping("/api/timeseries/{assetId}/current")
    public ResponseEntity<?> getCurrentValues(@PathVariable String assetId) {
        String query = String.format(
            "from(bucket: \"aas_timeseries\") " +
            "|> range(start: -1m) " +
            "|> filter(fn: (r) => r.asset_id == \"%s\") " +
            "|> last()",
            assetId
        );

        List<FluxTable> tables = influxDBClient.getQueryApi().query(query);
        return ResponseEntity.ok(convertToJson(tables));
    }

    // ì‹œê°„ ë²”ìœ„ ì¡°íšŒ
    @GetMapping("/api/timeseries/{assetId}/history")
    public ResponseEntity<?> getHistoricalData(
            @PathVariable String assetId,
            @RequestParam String start,
            @RequestParam String end,
            @RequestParam(defaultValue = "1m") String interval) {

        String query = String.format(
            "from(bucket: \"aas_timeseries\") " +
            "|> range(start: %s, stop: %s) " +
            "|> filter(fn: (r) => r.asset_id == \"%s\") " +
            "|> aggregateWindow(every: %s, fn: mean)",
            start, end, assetId, interval
        );

        List<FluxTable> tables = influxDBClient.getQueryApi().query(query);
        return ResponseEntity.ok(convertToJson(tables));
    }

    // í†µê³„ ì¡°íšŒ
    @GetMapping("/api/timeseries/{assetId}/stats")
    public ResponseEntity<?> getStatistics(
            @PathVariable String assetId,
            @RequestParam String period) {

        String query = String.format(
            "from(bucket: \"aas_timeseries\") " +
            "|> range(start: -%s) " +
            "|> filter(fn: (r) => r.asset_id == \"%s\") " +
            "|> group(columns: [\"_field\"]) " +
            "|> reduce(fn: (r, accumulator) => ({" +
            "    count: accumulator.count + 1," +
            "    sum: accumulator.sum + r._value," +
            "    min: if r._value < accumulator.min then r._value else accumulator.min," +
            "    max: if r._value > accumulator.max then r._value else accumulator.max" +
            "}))",
            period, assetId
        );

        List<FluxTable> tables = influxDBClient.getQueryApi().query(query);
        return ResponseEntity.ok(convertToJson(tables));
    }
}
```

### 5. AASì™€ ì‹œê³„ì—´ ë°ì´í„° í†µí•©

```java
// AasTimeSeriesIntegrationService.java
@Service
public class AasTimeSeriesIntegrationService {

    @Autowired
    private AasRepository aasRepository;

    @Autowired
    private TimeSeriesQueryService timeSeriesService;

    // AAS ì •ë³´ì™€ ì‹¤ì‹œê°„ ë°ì´í„° í†µí•© ì¡°íšŒ
    @GetMapping("/api/aas/{aasId}/with-realtime")
    public ResponseEntity<?> getAasWithRealtimeData(@PathVariable String aasId) {
        // 1. AAS ì •ì  ì •ë³´ ì¡°íšŒ
        AssetAdministrationShell aas = aasRepository.findById(aasId);

        // 2. í˜„ì¬ ì„¼ì„œ ê°’ ì¡°íšŒ
        Map<String, Object> currentValues = timeSeriesService
            .getCurrentValues(aas.getAssetId());

        // 3. í†µí•© ì‘ë‹µ
        Map<String, Object> response = new HashMap<>();
        response.put("aas", aas);
        response.put("currentValues", currentValues);
        response.put("dataSourceUrl", "/api/timeseries/" + aas.getAssetId());

        return ResponseEntity.ok(response);
    }
}
```

### 6. í”„ë¡ íŠ¸ì—”ë“œ í†µí•©

```javascript
// useTimeSeriesData.js
import { ref, onMounted, onUnmounted } from 'vue'
import axios from 'axios'

export function useTimeSeriesData(assetId) {
  const currentData = ref({})
  const historicalData = ref([])
  const isLoading = ref(false)
  let intervalId = null

  // ì‹¤ì‹œê°„ ë°ì´í„° í´ë§
  const fetchCurrentData = async () => {
    try {
      const response = await axios.get(`/api/timeseries/${assetId}/current`)
      currentData.value = response.data
    } catch (error) {
      console.error('Failed to fetch current data:', error)
    }
  }

  // íˆìŠ¤í† ë¦¬ ë°ì´í„° ì¡°íšŒ
  const fetchHistoricalData = async (start, end, interval = '1m') => {
    isLoading.value = true
    try {
      const response = await axios.get(`/api/timeseries/${assetId}/history`, {
        params: { start, end, interval },
      })
      historicalData.value = response.data
    } catch (error) {
      console.error('Failed to fetch historical data:', error)
    } finally {
      isLoading.value = false
    }
  }

  // ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì‹œì‘
  const startRealTimeUpdates = (intervalMs = 5000) => {
    fetchCurrentData() // ì¦‰ì‹œ í•œë²ˆ ì‹¤í–‰
    intervalId = setInterval(fetchCurrentData, intervalMs)
  }

  // ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì¤‘ì§€
  const stopRealTimeUpdates = () => {
    if (intervalId) {
      clearInterval(intervalId)
      intervalId = null
    }
  }

  onMounted(() => {
    startRealTimeUpdates()
  })

  onUnmounted(() => {
    stopRealTimeUpdates()
  })

  return {
    currentData,
    historicalData,
    isLoading,
    fetchHistoricalData,
    startRealTimeUpdates,
    stopRealTimeUpdates,
  }
}
```

### 7. ì„±ëŠ¥ ìµœì í™” ì „ëµ

#### ë°ì´í„° ë³´ì¡´ ì •ì±…

```sql
-- InfluxDB ë³´ì¡´ ì •ì±…
CREATE RETENTION POLICY "one_week" ON "aas_timeseries" DURATION 1w REPLICATION 1 DEFAULT
CREATE RETENTION POLICY "one_month" ON "aas_timeseries" DURATION 4w REPLICATION 1
CREATE RETENTION POLICY "one_year" ON "aas_timeseries" DURATION 52w REPLICATION 1

-- ì—°ì† ì¿¼ë¦¬ë¡œ ë‹¤ìš´ìƒ˜í”Œë§
CREATE CONTINUOUS QUERY "downsample_1h" ON "aas_timeseries"
BEGIN
  SELECT mean(*) INTO "one_month"."downsampled"
  FROM "one_week"."sensor_data"
  GROUP BY time(1h), *
END
```

#### ìºì‹± ì „ëµ

```java
@Configuration
@EnableCaching
public class CacheConfig {

    @Bean
    public CacheManager cacheManager() {
        return new ConcurrentMapCacheManager("currentValues", "statistics");
    }
}

// ì„œë¹„ìŠ¤ì—ì„œ ìºì‹œ ì‚¬ìš©
@Cacheable(value = "currentValues", key = "#assetId")
public Map<String, Object> getCurrentValues(String assetId) {
    // ì‹¤ì œ ì¡°íšŒ ë¡œì§
}

@CacheEvict(value = "currentValues", key = "#assetId")
@Scheduled(fixedDelay = 5000) // 5ì´ˆë§ˆë‹¤ ìºì‹œ ê°±ì‹ 
public void evictCurrentValuesCache() {
    // ìºì‹œ ë¬´íš¨í™”
}
```

### 8. ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼

```java
// AlertingService.java
@Service
public class AlertingService {

    @Value("${alert.threshold.pressure.max}")
    private double maxPressure;

    @EventListener
    public void checkThresholds(SensorDataEvent event) {
        SensorData data = event.getSensorData();

        // ì„ê³„ê°’ ì²´í¬
        if (data.getPressure() > maxPressure) {
            sendAlert(AlertType.HIGH_PRESSURE, data);
        }

        // ì´ìƒ íŒ¨í„´ ê°ì§€
        if (isAnomalous(data)) {
            sendAlert(AlertType.ANOMALY, data);
        }
    }

    private void sendAlert(AlertType type, SensorData data) {
        // ì•Œë¦¼ ë°œì†¡ ë¡œì§
        notificationService.send(
            String.format("Alert: %s detected for asset %s",
                type, data.getAssetId())
        );
    }
}
```

## ğŸ“Š ì•„í‚¤í…ì²˜ ë¹„êµ

| í•­ëª©        | ì§ì ‘ ì—…ë°ì´íŠ¸ ë°©ì‹ | ì‹œê³„ì—´ DB ë¶„ë¦¬ ë°©ì‹ |
| ----------- | ------------------ | ------------------- |
| ì“°ê¸° ì„±ëŠ¥   | âŒ ë‚®ìŒ            | âœ… ë†’ìŒ             |
| ì¡°íšŒ ì„±ëŠ¥   | âŒ ë‚®ìŒ            | âœ… ë†’ìŒ             |
| í™•ì¥ì„±      | âŒ ì œí•œì           | âœ… ìš°ìˆ˜             |
| ë°ì´í„° ì••ì¶• | âŒ ì—†ìŒ            | âœ… ìë™             |
| ì‹œê³„ì—´ ë¶„ì„ | âŒ ì–´ë ¤ì›€          | âœ… ì‰¬ì›€             |
| êµ¬í˜„ ë³µì¡ë„ | âœ… ë‹¨ìˆœ            | âš ï¸ ì¤‘ê°„             |
| ìœ ì§€ë³´ìˆ˜    | âŒ ì–´ë ¤ì›€          | âœ… ì‰¬ì›€             |

## ğŸ¯ ê¶Œì¥ì‚¬í•­

1. **ì†Œê·œëª¨ ì‹œì‘**: InfluxDB + ë‹¨ìˆœ í´ë§
2. **ì¤‘ê·œëª¨**: InfluxDB + Kafka + ìºì‹±
3. **ëŒ€ê·œëª¨**: TimescaleDB/Druid + Kafka + Redis

ì´ ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ë©´ AASì˜ ì •ì  ì •ë³´ì™€ ì‹¤ì‹œê°„ ì„¼ì„œ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë¶„ë¦¬ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
